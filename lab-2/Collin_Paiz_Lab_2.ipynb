{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60cd42d4-737b-42c9-a70a-d00880b45ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102080\n",
      "        0  00  000  000016447  00010563n  0002  0004287  0005173miami050  \\\n",
      "0       0   0    0          0          0     0        0                0   \n",
      "1       0   0    0          0          0     0        0                0   \n",
      "2       0   0    0          0          0     0        0                0   \n",
      "3       0   0    0          0          0     0        0                0   \n",
      "4       0   0    0          0          0     0        0                0   \n",
      "...    ..  ..  ...        ...        ...   ...      ...              ...   \n",
      "102075  0   0    0          0          0     0        0                0   \n",
      "102076  0   0    0          0          0     0        0                0   \n",
      "102077  0   0    0          0          0     0        0                0   \n",
      "102078  0   0    0          0          0     0        0                0   \n",
      "102079  0   0    0          0          0     0        0                0   \n",
      "\n",
      "        0009875buffalo040  000bn  ...  zwick  zwiki  zy  zydrunas  zygmunt  \\\n",
      "0                       0      0  ...      0      0   0         0        0   \n",
      "1                       0      0  ...      0      0   0         0        0   \n",
      "2                       0      0  ...      0      0   0         0        0   \n",
      "3                       0      0  ...      0      0   0         0        0   \n",
      "4                       0      0  ...      0      0   0         0        0   \n",
      "...                   ...    ...  ...    ...    ...  ..       ...      ...   \n",
      "102075                  0      0  ...      0      0   0         0        0   \n",
      "102076                  0      0  ...      0      0   0         0        0   \n",
      "102077                  0      0  ...      0      0   0         0        0   \n",
      "102078                  0      0  ...      0      0   0         0        0   \n",
      "102079                  0      0  ...      0      0   0         0        0   \n",
      "\n",
      "        zyman  zyprexa  zz  zzz  zzzzzz  \n",
      "0           0        0   0    0       0  \n",
      "1           0        0   0    0       0  \n",
      "2           0        0   0    0       0  \n",
      "3           0        0   0    0       0  \n",
      "4           0        0   0    0       0  \n",
      "...       ...      ...  ..  ...     ...  \n",
      "102075      0        0   0    0       0  \n",
      "102076      0        0   0    0       0  \n",
      "102077      0        0   0    0       0  \n",
      "102078      0        0   0    0       0  \n",
      "102079      0        0   0    0       0  \n",
      "\n",
      "[102080 rows x 61375 columns]\n",
      "25520\n",
      "       0  00  000  000660  000m  000mph  000th  001  005930  00am  ...  \\\n",
      "0      0   0    0       0     0       0      0    0       0     0  ...   \n",
      "1      0   0    0       0     0       0      0    0       0     0  ...   \n",
      "2      0   0    0       0     0       0      0    0       0     0  ...   \n",
      "3      0   0    0       0     0       0      0    0       0     0  ...   \n",
      "4      0   0    0       0     0       0      0    0       0     0  ...   \n",
      "...   ..  ..  ...     ...   ...     ...    ...  ...     ...   ...  ...   \n",
      "25515  0   0    0       0     0       0      0    0       0     0  ...   \n",
      "25516  0   0    0       0     0       0      0    0       0     0  ...   \n",
      "25517  0   0    0       0     0       0      0    0       0     0  ...   \n",
      "25518  0   0    0       0     0       0      0    0       0     0  ...   \n",
      "25519  0   0    0       0     0       0      0    0       0     0  ...   \n",
      "\n",
      "       zukauskas  zulf  zuma  zuo  zurab  zurich  zviadauri  zvidauri  \\\n",
      "0              0     0     0    0      0       0          0         0   \n",
      "1              0     0     0    0      0       0          0         0   \n",
      "2              0     0     0    0      0       0          0         0   \n",
      "3              0     0     0    0      0       0          0         0   \n",
      "4              0     0     0    0      0       0          0         0   \n",
      "...          ...   ...   ...  ...    ...     ...        ...       ...   \n",
      "25515          0     0     0    0      0       0          0         0   \n",
      "25516          0     0     0    0      0       0          0         0   \n",
      "25517          0     0     0    0      0       0          0         0   \n",
      "25518          0     0     0    0      0       0          0         0   \n",
      "25519          0     0     0    0      0       0          0         0   \n",
      "\n",
      "       zvonareva  zyman  \n",
      "0              0      0  \n",
      "1              0      0  \n",
      "2              0      0  \n",
      "3              0      0  \n",
      "4              0      0  \n",
      "...          ...    ...  \n",
      "25515          0      0  \n",
      "25516          0      0  \n",
      "25517          0      0  \n",
      "25518          0      0  \n",
      "25519          0      0  \n",
      "\n",
      "[25520 rows x 36560 columns]\n",
      "14.842570066452026\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix\n",
    "import string\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import sklearn as sk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import math\n",
    "import time\n",
    "\n",
    "def problemOne(file_name):\n",
    "    doc = []\n",
    "    file = open(file_name, 'r')\n",
    "    for line in file:\n",
    "        doc.append(line)\n",
    "    \n",
    "    cv = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\")   \n",
    "    count_occurrences = cv.fit_transform(doc)\n",
    "    \n",
    "    count_occurrences.toarray()\n",
    "    \n",
    "    count_vect_df = pd.DataFrame(data = count_occurrences.toarray(), columns=cv.get_feature_names_out())\n",
    "    \n",
    "    print(count_vect_df)\n",
    "    \n",
    "    \n",
    "start = time.time()\n",
    "problemOne('train.dat')\n",
    "problemOne('test.dat')\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3f23f14-dfe0-4531-9b57-27767b42d1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [nrows 25520, ncols 194175, nnz 849425]\n",
      " [nrows 102080, ncols 194175, nnz 3497809]\n",
      "5.028883934020996\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix\n",
    "import string\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import sklearn as sk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import math\n",
    "import time\n",
    "\n",
    "def build_both_ids(both):\n",
    "    r\"\"\" Build a mapping from word to ID and vice versa. \n",
    "    \"\"\"\n",
    "    both_idx = {}\n",
    "    tid = 0\n",
    "    for d in both:\n",
    "        for w in d:\n",
    "            w.lower()\n",
    "            if w not in both_idx:\n",
    "                both_idx[w] = tid\n",
    "                tid += 1\n",
    "    return both_idx\n",
    "\n",
    "def build_matrix(docs, idx):\n",
    "    r\"\"\" Build sparse matrix from a list of documents, \n",
    "    each of which is a list of word/terms in the document.  \n",
    "    \"\"\"\n",
    "    nrows = len(docs)\n",
    "    # tid = 0\n",
    "    nnz = 0\n",
    "    for d in docs:\n",
    "        nnz += len(set(d))\n",
    "    #     for w in d:\n",
    "    #         w.lower()\n",
    "    #         if w not in idx:\n",
    "    #             idx[w] = tid\n",
    "    #             tid += 1\n",
    "    ncols = len(idx)\n",
    "        \n",
    "    # set up memory\n",
    "    ind = np.zeros(nnz, dtype=int)\n",
    "    val = np.zeros(nnz, dtype=np.double)\n",
    "    ptr = np.zeros(nrows+1, dtype=int)\n",
    "    i = 0  # document ID / row counter\n",
    "    n = 0  # non-zero counter\n",
    "    # transfer values\n",
    "    for d in docs:\n",
    "        cnt = Counter(d)\n",
    "        keys = list(k for k,_ in cnt.most_common())\n",
    "        l = len(keys)\n",
    "        for j,k in enumerate(keys):\n",
    "            ind[j+n] = idx[k]\n",
    "            val[j+n] = cnt[k]\n",
    "        ptr[i+1] = ptr[i] + l\n",
    "        n += l\n",
    "        i += 1\n",
    "            \n",
    "    mat = csr_matrix((val, ind, ptr), shape=(nrows, ncols), dtype=np.double)\n",
    "    mat.sort_indices()\n",
    "    \n",
    "    return mat\n",
    "\n",
    "def csr_info(mat, name=\"\", non_empy=False):\n",
    "    r\"\"\" Print out info about this CSR matrix. If non_empy, \n",
    "    report number of non-empty rows and cols as well\n",
    "    \"\"\"\n",
    "    if non_empy:\n",
    "        print(\"%s [nrows %d (%d non-empty), ncols %d (%d non-empty), nnz %d]\" % (\n",
    "                name, mat.shape[0], \n",
    "                sum(1 if mat.indptr[i+1] > mat.indptr[i] else 0 \n",
    "                for i in range(mat.shape[0])), \n",
    "                mat.shape[1], len(np.unique(mat.indices)), \n",
    "                len(mat.data)))\n",
    "    else:\n",
    "        print( \"%s [nrows %d, ncols %d, nnz %d]\" % (name, \n",
    "                mat.shape[0], mat.shape[1], len(mat.data)) )\n",
    "\n",
    "def csr_l2normalize(mat, copy=False, **kargs):\n",
    "    r\"\"\" Normalize the rows of a CSR matrix by their L-2 norm. \n",
    "    If copy is True, returns a copy of the normalized matrix.\n",
    "    \"\"\"\n",
    "    if copy is True:\n",
    "        mat = mat.copy()\n",
    "    nrows = mat.shape[0]\n",
    "    nnz = mat.nnz\n",
    "    ind, val, ptr = mat.indices, mat.data, mat.indptr\n",
    "    # normalize\n",
    "    for i in range(nrows):\n",
    "        rsum = 0.0    \n",
    "        for j in range(ptr[i], ptr[i+1]):\n",
    "            rsum += val[j]**2\n",
    "        if rsum == 0.0:\n",
    "            continue  # do not normalize empty rows\n",
    "        rsum = 1.0/np.sqrt(rsum)\n",
    "        for j in range(ptr[i], ptr[i+1]):\n",
    "            val[j] *= rsum\n",
    "            \n",
    "    if copy is True:\n",
    "        return mat\n",
    "        \n",
    "# def textToMatrix(file, idx):\n",
    "#     docs = [l.split() for l in file]\n",
    "#     return build_matrix(docs, idx)\n",
    "\n",
    "def both(file1, file2):\n",
    "    docs1 = [l.split() for l in file1]\n",
    "    docs2 = [l.split() for l in file2]\n",
    "    doc_both = docs1 + docs2\n",
    "    return docs1, docs2, doc_both\n",
    "\n",
    "start = time.time()\n",
    "test = open('test.dat', 'r')\n",
    "train = open('train.dat', 'r')\n",
    "\n",
    "docs1, docs2, doc_both = both(test, train)\n",
    "idx = build_both_ids(doc_both)\n",
    "csr_info(build_matrix(docs1, idx))\n",
    "csr_info(build_matrix(docs2, idx))\n",
    "\n",
    "print(time.time() - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
